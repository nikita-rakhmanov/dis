# RNN Music Model - Optimization Analysis & Progress Tracker

**Date Started**: 2025-11-11
**Current Model**: Single LSTM(128) with 3-head output
**Training Data**: MAESTRO v2.0.0 (1000 files)

---

## Current Model Architecture

```
Input: (25, 3) [pitch, step, duration]
    ‚Üì
LSTM(128 units)
    ‚Üì
‚îú‚îÄ‚Üí Dense(128) ‚Üí Pitch prediction
‚îú‚îÄ‚Üí Dense(1) ‚Üí Step prediction
‚îî‚îÄ‚Üí Dense(1) ‚Üí Duration prediction
```

**Parameters**:
- Sequence Length: 25 notes
- Vocab Size: 128 (MIDI notes)
- Batch Size: 64
- Epochs: 50
- Learning Rate: 0.005 (Adam)
- Loss Weights: `{pitch: 0.05, step: 1.0, duration: 1.0}`

---

## Performance Baseline

### Current Model Characteristics
- **Total Parameters**: ~199K (estimated)
- **Single LSTM Layer**: 128 units
- **Training Time**: ~50 epochs with early stopping
- **Generation Quality**:
  - Timing: Good (heavily weighted)
  - Melodic coherence: Weak (pitch under-weighted at 0.05)
  - Long-term structure: Limited (short 25-note context)

### Known Issues
1. ‚ùå Pitch loss weight too low (0.05 vs 1.0 for timing)
2. ‚ùå Very short sequence length (25 notes)
3. ‚ùå Shallow architecture (1 layer)
4. ‚ùå No regularization (dropout)
5. ‚ùå No validation set
6. ‚ùå Only uses first instrument (no polyphony)

---

## Optimization Priority Tiers

### üî¥ HIGH PRIORITY (Start Here)

#### 1. Loss Weight Rebalancing
**Current**: `{pitch: 0.05, step: 1.0, duration: 1.0}`
**Target**: `{pitch: 0.5, step: 1.0, duration: 1.0}`

**Rationale**: Pitch is 20x under-weighted, causing poor melodic structure

**Expected Impact**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Better note selection
- More musical coherence
- Improved melodic patterns

**Implementation Difficulty**: üü¢ Trivial (1-line change)

---

#### 2. Increase Sequence Length
**Current**: 25 notes
**Target**: 50-100 notes

**Rationale**: 25 notes ‚âà 10-15 seconds of music; too short for musical phrases

**Expected Impact**: ‚≠ê‚≠ê‚≠ê‚≠ê
- Better long-term structure
- Captures musical motifs
- More coherent compositions

**Implementation Difficulty**: üü¢ Easy (change constant, retrain)

**Trade-offs**:
- ‚úÖ Better musical memory
- ‚ö†Ô∏è 2-4x more GPU memory
- ‚ö†Ô∏è Slower training (~20-30%)

---

#### 3. Deeper Architecture
**Current**: Single LSTM(128)
**Proposed Options**: See detailed architecture analysis below

**Expected Impact**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Captures complex patterns
- Better generalization
- Richer musical representations

**Implementation Difficulty**: üü° Moderate (architecture redesign)

---

### üü° MEDIUM PRIORITY

#### 4. Add Dropout Regularization
**Target**: 0.2-0.3 dropout rate

**Expected Impact**: ‚≠ê‚≠ê‚≠ê
- Reduces overfitting
- Better generalization
- More diverse outputs

---

#### 5. Train/Validation Split
**Target**: 90/10 split

**Expected Impact**: ‚≠ê‚≠ê‚≠ê
- Monitor overfitting
- Better hyperparameter tuning
- Early stopping on validation loss

---

#### 6. Learning Rate Scheduling
**Options**:
- ExponentialDecay
- ReduceLROnPlateau

**Expected Impact**: ‚≠ê‚≠ê‚≠ê
- Faster convergence
- Better final performance
- Escape local minima

---

### üü¢ LOW PRIORITY (Future Work)

7. Data augmentation (transposition, time stretching)
8. Polyphony support (chord generation)
9. Add velocity as 4th feature
10. Attention mechanisms
11. Transformer architecture
12. Conditional generation (style/genre control)

---

## Architecture Comparison Matrix

See detailed analysis in **ARCHITECTURE_OPTIONS** section below.

| Architecture | Params | Training Speed | Quality | Memory | Complexity |
|--------------|--------|----------------|---------|--------|------------|
| **Current (Baseline)** | 199K | ‚ö°‚ö°‚ö° Fast | ‚≠ê‚≠ê | Low | Simple |
| **Option A: Stacked LSTM** | 528K | ‚ö°‚ö° Moderate | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium | Moderate |
| **Option B: Bidirectional** | 398K | ‚ö°‚ö° Moderate | ‚≠ê‚≠ê‚≠ê‚≠ê | Medium | Moderate |
| **Option C: LSTM+Dense** | 223K | ‚ö°‚ö°‚ö° Fast | ‚≠ê‚≠ê‚≠ê | Low | Simple |
| **Option D: Hybrid (A+C)** | 552K | ‚ö° Slower | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | High | Complex |

---

## Experiment Tracking

### Experiment 1: Baseline (Current Model)
**Status**: ‚úÖ Completed
**Date**: [Original training date]

**Configuration**:
- Architecture: Single LSTM(128)
- Sequence Length: 25
- Loss Weights: `{pitch: 0.05, step: 1.0, duration: 1.0}`
- Learning Rate: 0.005

**Results**:
- Final Loss: [TBD - check training logs]
- Pitch Accuracy: [TBD]
- Step MAE: [TBD]
- Duration MAE: [TBD]

**Observations**:
- Good timing generation
- Weak melodic structure
- Limited long-term coherence

---

### Experiment 2: [NEXT] Loss Weight Rebalancing
**Status**: ‚è≥ Pending

**Configuration**:
- Architecture: Single LSTM(128)
- Sequence Length: 25
- Loss Weights: `{pitch: 0.5, step: 1.0, duration: 1.0}` ‚¨ÖÔ∏è CHANGED
- Learning Rate: 0.005

**Hypothesis**: 10x increase in pitch weight will improve melodic quality without sacrificing timing

**Expected Results**:
- ‚úÖ Better pitch selection
- ‚úÖ More musical melodies
- ‚ö†Ô∏è Slightly worse timing (acceptable trade-off)

**Results**: [Run and record]

---

### Experiment 3: [FUTURE] Increased Sequence Length
**Status**: ‚è≥ Pending

**Configuration**:
- Architecture: Single LSTM(128)
- Sequence Length: 50 ‚¨ÖÔ∏è CHANGED
- Loss Weights: `{pitch: 0.5, step: 1.0, duration: 1.0}`
- Learning Rate: 0.005

---

### Experiment 4: [FUTURE] New Architecture
**Status**: ‚è≥ Pending

**Configuration**: [TBD based on architecture decision]

---

## Implementation Checklist

### Phase 1: High Priority (This Week)
- [ ] **Fix Loss Weights**
  - [ ] Change pitch weight from 0.05 ‚Üí 0.5
  - [ ] Retrain model
  - [ ] Compare generated music quality
  - [ ] Document results in Experiment 2

- [ ] **Increase Sequence Length**
  - [ ] Change SEQUENCE_LENGTH from 25 ‚Üí 50
  - [ ] Update seed sequence generation
  - [ ] Retrain model
  - [ ] Monitor memory usage
  - [ ] Document results in Experiment 3

- [ ] **Choose & Implement New Architecture**
  - [ ] Review architecture options (see below)
  - [ ] Implement chosen architecture
  - [ ] Add dropout layers
  - [ ] Retrain model
  - [ ] Compare all metrics
  - [ ] Document results in Experiment 4

### Phase 2: Medium Priority (Next Week)
- [ ] Add train/validation split
- [ ] Implement validation metrics
- [ ] Add learning rate scheduling
- [ ] Add ReduceLROnPlateau callback

### Phase 3: Low Priority (Future)
- [ ] Data augmentation
- [ ] Polyphony support
- [ ] Velocity modeling

---

## Notes & Observations

### Training Tips
- Monitor both loss AND generated music quality (subjective listening tests)
- Save checkpoints every 5 epochs for rollback
- Use TensorBoard for visualization
- Test generation at multiple temperature values (0.8, 1.0, 1.5, 2.0)

### Common Issues
- If loss doesn't decrease: Learning rate too high or too low
- If overfitting: Add dropout or reduce model size
- If output too repetitive: Increase temperature or sequence length
- If output too random: Decrease temperature or increase training epochs

---

## Resources
- Training script: `train_music_rnn.py`
- Generation script: `realtime_midi_generator.py`
- Model file: `music_rnn_model.keras`
- Dataset: MAESTRO v2.0.0 (1000 files)
- Checkpoints: `training_checkpoints/ckpt_*.weights.h5`

---

## Quick Reference: Code Locations

**Loss Weights**: `train_music_rnn.py:128-132`
```python
loss_weights={
    'pitch': 0.05,  # ‚¨ÖÔ∏è CHANGE THIS
    'step': 1.0,
    'duration': 1.0,
}
```

**Sequence Length**: `train_music_rnn.py:18`
```python
SEQUENCE_LENGTH = 25  # ‚¨ÖÔ∏è CHANGE THIS
```

**Model Architecture**: `train_music_rnn.py:105-136`
```python
def build_model(seq_length: int, vocab_size: int, learning_rate: float):
    # ‚¨ÖÔ∏è MODIFY THIS FUNCTION
```

---

*Last Updated: 2025-11-11*
