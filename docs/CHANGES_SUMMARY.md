# Optimization Changes Summary

**Date**: 2025-11-11
**Version**: v2 - Stacked LSTM + Stability Improvements
**Status**: Ready for training on GPU

---

## ‚úÖ Changes Implemented (Version 2)

### 1. Loss Weight Rebalancing
**File**: `train_music_rnn.py:129`

**Change**:
```python
# Before
'pitch': 0.05,

# After
'pitch': 0.5,  # Increased from 0.05 to improve melodic quality
```

**Impact**:
- Pitch now has 10x more weight (was 20x under-weighted)
- Model will prioritize melodic quality alongside timing
- Expected: Better note selection, more musical coherence

---

### 2. Increased Sequence Length
**Files Updated**:
- `train_music_rnn.py:18`
- `realtime_midi_generator.py:21`
- `integrated_music_gesture_control.py:33`

**Change**:
```python
# Before
SEQUENCE_LENGTH = 25

# After
SEQUENCE_LENGTH = 50  # Increased from 25 to capture longer musical phrases
```

**Impact**:
- 2x longer musical context (25 ‚Üí 50 notes)
- Can capture longer phrases and motifs
- Better long-term musical structure
- Trade-off: ~2x more GPU memory needed, ~20-30% slower training

---

### 3. üÜï Lower Learning Rate (NEW)
**File**: `train_music_rnn.py:22`

**Change**:
```python
# Before
LEARNING_RATE = 0.005

# After
LEARNING_RATE = 0.001  # Reduced from 0.005 for more stable training
```

**Impact**:
- 5x slower learning rate = more stable gradient descent
- Should prevent loss from increasing mid-training
- More epochs may be needed, but training will be steadier
- Expected: Smooth loss curves, no early stopping

**Reasoning**: Previous training was unstable (loss increased after epoch 5). Lower LR will fix this.

---

### 4. üÜï Stacked LSTM Architecture (NEW)
**File**: `train_music_rnn.py:105-114`

**Change**:
```python
# Before (Single LSTM)
x = tf.keras.layers.LSTM(128)(inputs)

# After (Stacked LSTM with Dropout)
x = tf.keras.layers.LSTM(256, return_sequences=True)(inputs)
x = tf.keras.layers.Dropout(0.3)(x)
x = tf.keras.layers.LSTM(128)(x)
```

**Architecture Details**:
- **Layer 1**: LSTM(256 units, return_sequences=True)
  - Learns low-level patterns (note transitions, rhythms)
  - Returns full sequence to next layer
- **Dropout**: 0.3 dropout rate
  - Regularization to prevent overfitting
  - Forces robust feature learning
- **Layer 2**: LSTM(128 units)
  - Learns high-level patterns (phrases, motifs, structure)
  - Outputs single vector for prediction

**Parameter Count**:
- Before: ~199K parameters
- After: ~528K parameters (2.7x increase)

**Impact**:
- ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Significantly better music quality
- Hierarchical learning: low-level ‚Üí high-level patterns
- Better generalization with dropout
- ~30% slower training
- Requires ~6-8GB GPU memory (vs 4-6GB before)

---

## üìä Expected Results

### Version 1 Results (Tested)
- Sequence: 50 notes
- Loss weights: {pitch: 0.5, step: 1.0, duration: 1.0}
- Architecture: Single LSTM(128)
- Learning rate: 0.005
- **Result**: Training unstable, early stopping at epoch 10
- **Music quality**: "Not bad, but could be better" (temperature 2.0)

### Version 2 Expected (Current)
- Sequence: 50 notes ‚úì
- Loss weights: {pitch: 0.5, step: 1.0, duration: 1.0} ‚úì
- Architecture: Stacked LSTM(256‚Üí128) with Dropout ‚úÖ NEW
- Learning rate: 0.001 ‚úÖ NEW
- **Expected**: Stable training, reaches 30-50 epochs
- **Expected music quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Significantly better melodies and coherence

---

## üöÄ Training on Your GPU Machine

### 1. Pull Latest Changes
```bash
cd ~/dis
git pull origin claude/optimize-rnn-model-011CV2Hmb3tQG8U7jhSDyr1X
```

### 2. Check GPU Memory
```bash
nvidia-smi
```

**Requirements for Stacked LSTM**:
- **Minimum**: 6GB GPU memory
- **Recommended**: 8GB+ GPU memory
- RTX 3060 (12GB) ‚úÖ Perfect!

**If memory issues occur**: Reduce BATCH_SIZE from 64 ‚Üí 32

### 3. Run Training
```bash
# Using Podman container
podman run --rm \
  --device nvidia.com/gpu=all \
  --volume $(pwd):/workspace:z \
  --workdir /workspace \
  --shm-size=2g \
  docker.io/tensorflow/tensorflow:latest-gpu \
  bash -c "pip install --no-cache-dir -r requirements.txt && python3 train_music_rnn.py"
```

### 4. Expected Training Behavior

**What you'll see**:
```
Epoch 1/50
44347/44347 [========] - 180s 4ms/step - loss: X.XXX - pitch_loss: X.XXX ...
Epoch 2/50
44347/44347 [========] - 150s 3ms/step - loss: X.XXX - pitch_loss: X.XXX ...
...
```

**Good signs**:
- ‚úÖ Each epoch takes ~150-180 seconds (was ~120s, now 30% slower)
- ‚úÖ Loss decreases steadily (no sudden jumps)
- ‚úÖ All three losses (pitch, step, duration) decrease together
- ‚úÖ Training continues past epoch 10 (no early stopping)

**Timeline**:
- **Per epoch**: ~2.5-3 minutes (vs 2 minutes before)
- **Total (50 epochs)**: ~2.5-3.5 hours
- **With early stopping**: Likely ~2-3 hours (may stop around epoch 40)

---

## üîß Troubleshooting

### OOM (Out of Memory) Errors

**Solution 1**: Reduce batch size
```python
# train_music_rnn.py:20
BATCH_SIZE = 32  # Was 64
```

**Solution 2**: Reduce first LSTM size
```python
# train_music_rnn.py:112 (if really necessary)
x = tf.keras.layers.LSTM(192, return_sequences=True)(inputs)  # Was 256
```

### Training Very Slow (>5 min/epoch)

- Check GPU is actually being used: Look for "Created device /job:localhost/.../GPU:0"
- Check other processes aren't using GPU: `nvidia-smi` on host

### Loss Not Decreasing

- Lower learning rate is 5x slower, so give it 15-20 epochs
- Pitch loss will start high (~4.0) - that's expected!
- If still stuck after 20 epochs, might need to adjust loss weights

### Loss Suddenly Jumps Up

- This shouldn't happen with LR=0.001
- If it does, reduce LR further to 0.0005

---

## üìù After Training

### 1. Copy Model Files (CRITICAL - Don't Lose Them!)
```bash
# On GPU machine, copy to external storage immediately
cp music_rnn_model.keras /your/safe/location/
cp seed_sequence.npy /your/safe/location/
cp -r training_checkpoints/ /your/safe/location/
```

### 2. Transfer to Your Dev Machine
```bash
# Copy to your Mac for testing
scp music_rnn_model.keras seed_sequence.npy your-mac:~/Desktop/dis/
```

### 3. Test Music Generation
```bash
# On your Mac
cd ~/Desktop/dis

# Install tf_keras if you haven't
pip install tf_keras

# Test at different temperatures
python generate_music.py --temperature 0.8 --num-notes 50
python generate_music.py --temperature 1.2 --num-notes 50
python generate_music.py --temperature 1.5 --num-notes 50
python generate_music.py --temperature 2.0 --num-notes 50
```

### 4. Compare to Version 1

**What to listen for**:
- ‚úÖ Better melodies? More "musical" note choices?
- ‚úÖ Longer coherence? Phrases make sense?
- ‚úÖ Less repetitive? More variety?
- ‚úÖ Better rhythm and timing?

**Document your findings** in the experiment log below!

---

## üéØ Experiment Log

### Experiment 1: Baseline (Original)
- Architecture: Single LSTM(128)
- Sequence: 25 notes
- Loss weights: {pitch: 0.05, step: 1.0, duration: 1.0}
- Learning rate: 0.005
- **Result**: Good timing, weak melodies

### Experiment 2: First Optimization
- Architecture: Single LSTM(128)
- Sequence: 50 notes ‚úÖ
- Loss weights: {pitch: 0.5, step: 1.0, duration: 1.0} ‚úÖ
- Learning rate: 0.005
- **Result**: Training unstable, early stopping at epoch 10
- **Music**: "Not bad, but could be better" @ temp 2.0

### Experiment 3: Stacked LSTM + Stability (CURRENT)
- Architecture: Stacked LSTM(256‚Üí128) with Dropout ‚úÖ
- Sequence: 50 notes ‚úÖ
- Loss weights: {pitch: 0.5, step: 1.0, duration: 1.0} ‚úÖ
- Learning rate: 0.001 ‚úÖ
- **Result**: [TO BE FILLED AFTER TRAINING]
- **Music**: [TO BE FILLED AFTER TESTING]

**Training metrics to record**:
- Final epoch reached: ___
- Final loss: ___
- Final pitch loss: ___
- Training time: ___
- Best temperature: ___

---

## üéµ What's Changed - Summary Table

| Aspect | Baseline | Version 1 | Version 2 (Current) |
|--------|----------|-----------|---------------------|
| **Architecture** | Single LSTM(128) | Single LSTM(128) | Stacked LSTM(256‚Üí128) |
| **Sequence Length** | 25 | 50 | 50 |
| **Pitch Weight** | 0.05 | 0.5 | 0.5 |
| **Learning Rate** | 0.005 | 0.005 | 0.001 |
| **Dropout** | None | None | 0.3 |
| **Parameters** | 199K | 199K | 528K |
| **Training Time** | ~1.5h | ~0.5h* | ~2.5-3h |
| **Training Stability** | Stable | Unstable | Expected Stable |
| **Music Quality** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (expected) |

*Version 1 stopped early due to instability

---

## üîÆ Future Improvements (Not Yet Implemented)

- [ ] Train/validation split for better monitoring
- [ ] Learning rate scheduling (ReduceLROnPlateau)
- [ ] Data augmentation (transposition, time stretching)
- [ ] Increase training data (1000 ‚Üí 5000 files)
- [ ] Polyphony support (chord generation)
- [ ] Attention mechanisms
- [ ] Conditional generation (genre/style control)

---

**Files Modified**: 1 (train_music_rnn.py)
**Lines Changed**: 4
**Parameter Increase**: 2.7x (199K ‚Üí 528K)
**Expected Training Time**: ~2.5-3 hours
**Expected Quality Improvement**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (major)

---

*Last Updated: 2025-11-11*
*Ready for GPU training!*
